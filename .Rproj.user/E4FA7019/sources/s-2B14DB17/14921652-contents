---
title: 'Web Scraping in R : rvest'
author: "Inayatus"
date: "`r format(Sys.Date(), '%A, %B %d, %Y')`"
output:
  rmdformats::readthedown: 
    self_contained: true
    thumbnails: true
    lightbox: true
    gallery: false
    highlight: monochrome
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(ggplot2)
library(plotly)
library(ggthemes)
```

Mendownload data dari beberapa website penyedia data mungkin sudah biasa kita lakukan. Namun bagaimana jika kita ingin melakukan pengambilan data, namun data tersebut merupakan data dari website itu sendiri?
Nah disinilah yang disebut dengan melakukan scraping data. 

Trustpilot merupakan salah satu website yang cukup populer yang digunakan para pelanggan dalam melakukan ulasan mengenai bisnis dan pelayanan dari suatu e-commerce. Nah pada tutorial kali ini, kita akan belajar bagaimana cara scraping informasi yang berguna dari website Trustpilot lalu membuat insight sederhana dari data atau informasi yang akan kita dapatkan dengan menggunakan R. 

# Library Used

Nah sebelum melakukan scraping data dari website Trustpilot, kita memerlukan `package` yang harus kita install di lembar kerja R kita. Berikut ini beberapa `package` yang dapat digunakan.

```{r, message=FALSE, warning=FALSE}
# general purpose data wraling
library(tidyverse)

# parsing of HTML/XML files
library(rvest)

# string manipulation
library(stringr)

# Date time manipulation
library(lubridate)

# verbose regular expression
library(rebus)
```

# Find All Page

Sebagai contoh, misal kita akan melakukan pengambilan informasi tentang ulasan dari e-commerce seperti Amazon. Yang perlu kita butuhkan untuk mengambil informasi dari suatu website adalah dengan menggunakan URL pada website tersebut.

URL yang kita miliki itu nantinya akan kita simpan sebagai objek. 
```{r}
url <- 'https://www.trustpilot.com/review/www.amazon.com?page=225'
```
Biasanya dalam perusahaan besar, apalagi itu merupakan e-commerce, tentunya memiliki review yang sangat banyak, bisa lebih dari ratusan. 

Untuk memperoleh data dari website kita perlu menggunakan fungsi dari `rvest` package. Untuk mengubah website menjadi objek XML, kita gunakan function `read_html()`. Nah tapi jangan lupa untuk menyediakan URL target yang akan kita gunakan untuk mengumpulkan data, memanggil server web, dan memparsing data dari web tersebut. Untuk melakukan ekstraksi node dari XML objek kita gunakan `html_nodes()`, dan diiikuti dengan `.` untuk menandakan _class_ deskriptornya. Output yang akan dihasilkan adalah list dari semua node yang ditemukan. Untuk mengekstraksi _tagged data_, kita menggunakan `html_text()`pada node yang sudah kita temukan. Pada case ketika kita butuh mengekstraksi suatu atribut dalam website, kita gunakan `html_attrs()`. Function ini dapat mengembalikan atribut-atribut yang ingin kita atur ulang dan kita ekstrak. 

<br>
Nah yaudah gausah lama-lama, mari kita coba sama-sama. 

Pada tutorial kali ini, kita akn banyak bermain-main dengan menggunakan `fuction()` yang tujuannya adalah untuk mengekstraksi data-data yang akan kita ambil dari suatu website. Dalam `function` yang akan kita buat nantinya, kita perlu mengetahui _tag_ dari informasi yang akan kita ambil.

Karena kali ini saya ingin mencontohkan scrapping data dari e-commerce Amazon, berikut _tag_ yang kita perlukan.

 - `.pagination-page` : _tag_ untuk melihat berapa banyak halaman atau page review 
 - `.consumer-information__names` : _tag_ untuk mengtahui nama reviewer
 - `.star-rating` : _tag_ untuk mengetahui rating penilaian terhadap suatu e-commerce
 - `.review-content__text` : _tag_ untuk mengetahui review yang diberikan dari masing-masing reviewer
 - `.consumer-information__location` : _tag_ untuk mengetahui asal reviewer
 - `.consumer-information__review-count` : _tag_ untuk mengetahui reviewer pernah melakukan review berapa kali

 > Perlu diingat bahwa untuk masing-masing website memiliki nama _tag_ dan _class_ yang berbeda, sehingga harus disesuaikan untuk website tertentu
 
Berikut ini `function` yang dapat digunakan untuk beberapa _tag_ diatas.

```{r}
last.page <- function(html){
  pages.data <- html %>% 
    html_nodes('.pagination-page') %>%
    # ekstrak raw teks ke list
    html_text()
  # mengambil halaman kedua hingga terakhir
  pages.data[(length(pages.data))] %>%
    # mengambil raw string
    unname() %>% 
    # convert ke angka
    as.numeric()
}

```
Tahapan diatas mengaplikasikan function `html_nodes()` yang mana kita ingin mengekstrak `pagination` class. Fungsi yang terakhir yang dibuat adalah fungsi untuk mengambil item yang benar dari list, halaman kedua sampai terkahir, dan mengubahnya menjadi nilai numerik. 

Untuk melakukan testing terhadap fungsi yang kita buat bisa menggunakan function `read_html()` dan aplikasikan pada fungsi yang telah kita tulis :

```{r}
first.page <- read_html(url)
latest.page <- last.page(first.page)
```

Setelah memperoleh angka halaman akhir dari web reviewnya, kita bisa melihat URL apa saja yang berkaitan dengan review untuk Amazon.
```{r}
list.of.pages <- str_c(url, '?page=', 1:latest.page)
head(list.of.pages)
```

Kita dapat mengecek secara manual dari `list.of.pages` memang valid dan dapat diakses via web browser.

# Extract Information of One Page

Jika kita ingin mengekstrak teks review, rating, nama author, dan waktu dari pengumpulan review dari subpage. Kita dapat mengulangi langkah dari awal dari masing-masing _fields_ yang ingin kita cari.
```{r}
information <- function(html, tag){
  html %>% 
    # relevant tag
    html_nodes(tag) %>% 
    html_text() %>% 
    # trim additional white space
    str_trim() %>% 
    # mengubah dari list ke vector
    unlist()
}
```

Terakhir, kita akan membuat fungsi untuk mengekstrak rating review. Rating disebut sebagai atribut dalam tag. Rating bukan termasuk dalam angka, namun masuk dalam `star-rating-X`, di mana X adalah angka yang kita inginkan. 

Kita mengaplikasikan fungsi tersebut pada list URL yang akan kita generalisasikan. Untuk melakukannya, kita gunakan `map()` function dari `purrr` package yang mana termasuk dalam `tidyverse`.
```{r}
star.rating.information <- function(html){
  # pattern you look for : the first digit after 'star-rating-'
  pattern = 'star-rating-' %R% capture(DIGIT)
  
  rating <- html %>% 
    html_nodes('.star-rating') %>% 
    html_attrs() %>% 
    # apply the pattern match to all attribtes
    map(str_match, pattern = pattern) %>% 
    # str_match[1] is fully matched string, the second entry
    # is the part you extract with the capture in your pattern
    map(2) %>% 
    unlist()
  
  # leave out first instance, as it is not part of a review
  rating[3:length(rating)]
}
```

Selanjutnya yang terakhir adalah kita akan mengambil data tanggal atau waktu dari review memberikan review. 
```{r}
dates <- function(html){
  read_html(url) %>%
    html_nodes('.review-card .review__content .review-content .review-content__header  .review-content-header .review-content-header__dates') %>%
    html_text() %>%
    purrr::map(1) %>%
    # parse string into a datetime object with lubridate
    ymd_hms() %>%
    unlist()
}
```

Selanjutnya, kita akan gabungkan semua data yang kita ingin dapatkan dalam satu tabel.
```{r}
get.data.table <- function(html, company.name){
  # extract basic information from HTML
  name.review <- information(html, '.consumer-information__name')
  text.review <- information(html, '.review-content__text')
  location.review <- information(html, '.consumer-information__location')
  review.count <- information(html, '.consumer-information__review-count')
  rating <- star.rating.information(html)
  dates <- dates(html)
  
  #combine into tibble
  combine.data <- tibble(Name = name.review, Dates = dates, Review = text.review, Location = location.review, 
                         Review.count = review.count, Rating = rating)
  
  # tag individual data with the company name
  combine.data %>% 
    mutate(company = company.name) %>% 
    select(company, Name, Dates, Review, Location, Review.count, Rating)
}
```

```{r}
get.data.url <- function(url, company.name){
  html <- read_html(url)
  get.data.table(html, company.name)
}
```

Terakhir kalinya, kita akan memuat function untuk melakukan scrapping dari data-data yang ingin kita ambil dari URL yang telah kita pilih dengan memilih satu nama company dan menggabungkan semua hasil scraping data kita kedalam satu _tibble_. 
```{r}
scrape.table <- function(url, company.name){
  # baca halaman pertama
  first.page <- read_html(url)
  # ekstrak nomor halaman 
  latest.page <- last.page(first.page)
  # masukin target URL
  list.of.pages <- str_c(url, '?page=', 1:latest.page)
  
  # apply the extraction and bind the individuals resuts back into one table
  list.of.pages %>% 
    purrr::map(get.data.url, company.name) %>% 
    # combine the tibbles into one tibble
    bind_rows() %>% 
    # write a tab-eparated file
    write_tsv(str_c(company.name, '.tsv'))
}

```
Mari kita coba untuk scrap dari review yang diberikan untuk website Amazon.
```{r eval = FALSE}
temp <- scrape.table(url, 'amazon')
```


```{r}
# menyimpan data hasil scraping
amazon <- read_tsv('amazon.tsv')
head(amazon, 10)
```
# Visualisation Data {.tabset .tabset-fade .tabset-pills}

Beberapa data review yang diberikan beberapa orang sudah kita dapatkan. Berdasarkan hasil scraping yang diperoleh, terdapat 4500 reviewer yang memberikan review terhadap website Amazon. Dari 4500 reviewer yang memberikan review, jumlah rating yang diberikan berdasarkan banyak bintangnya adalah sebagai berikut.

## Total Rating

```{r, echo=FALSE, fig.width=8, warning=FALSE, message=FALSE}
# library(extrafont)
# font_import()
# loadfonts(device = "win")
amazon.new <- amazon %>% 
  mutate(Date = as.Date(Dates),
         Time = format(Dates, "%h:%m:%s"),
         rating = factor(Rating, levels = c(1:5), 
                         labels = c("Star 1", "Star 2", "Star 3", "Star 4", "Star 5")),
         Judgement = as.factor(case_when(rating == "Star 1"~"Worse",
                                      rating == "Star 2"~"Bad",
                                      rating == "Star 3"~"Good",
                                      rating == "Star 4"~"Better",
                                      rating == "Star 5"~"Best",
                                      TRUE ~ as.character(Rating))))
  
amazon.new %>% 
  arrange(rating, Judgement) %>% 
  group_by(rating, Judgement) %>% 
  summarise(freq = n()) %>% 
  ungroup() %>% 
  ggplot(aes(x = rating, y = freq)) +
  geom_col(aes(fill = rating)) + 
  geom_label(aes(label = factor(freq)), colour = "black", size = 3, nudge_y = 70, label.size = 0.15) +
  geom_text(aes(label = Judgement), position = position_stack(vjust = 0.5), angle = 90, size = 2.5, 
            color = c("black", "black", "black", "white", "white"), fontface = "bold") +
  labs(x = "Rating", y = "Amount of Rating", title = "Total Rating") +
  scale_fill_manual(values = c("#fadbe0", "#eaadbd", "#b88a9f", "#876880", "#554562")) +
  theme(title = element_text(size = 12, colour = "black", 
                             family = "Franklin Gothic Medium"),
        plot.title = element_text(hjust = 0.5),
        axis.title = element_text(size = 10, color = "black", family = "Calibri"),
        legend.title = element_text(size = 8, hjust = 0.2, vjust = 0.2, angle = 0.5, family = "Calibri"),
        legend.text = element_text(size = 8, hjust = 0.2, vjust = 0.2, angle = 0.5, family = "Calibri"),
        legend.box.background = element_blank(),
        legend.background = element_blank(),
        legend.key = element_blank(),
        axis.line = element_line(colour = "grey", size = 0.8),
        panel.grid.major.y = element_line(colour = "white", linetype = 1),
        panel.background = element_blank(),
        panel.grid.major.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        plot.margin = margin(1, 1, 1, 1, "cm"),
        plot.background = element_rect(colour = "grey", fill = "grey90", size = 1),
        legend.position = "bottom")
```

Dari grafik diatas, kita memperoleh informasi bahwa banyak reviewer yang memberikan rating 5 (Star 5) terhadap Amazon. Bila kita lihat pergerakan dari dari rata-rata rating tiap bulan dan mingguannya pada Amazon adalah sebagai berikut.

## Montly Average Rating

```{r}
library(xts)

amazon.ts <- xts(amazon.new$Rating, amazon.new$Date)
colnames(amazon.ts) <- 'Rating'
ended.interval <- '2009-01-01/'
amazon.xts <- amazon.ts[ended.interval]
avg.rating <- apply.monthly(amazon.xts, colMeans)
count.rating <- apply.monthly(amazon.xts, FUN = length)

```


```{r}
avg.rating <- avg.rating %>% 
  as.data.frame() 
avg.rating$month <- row.names(avg.rating)
# avg.rating <- avg.rating[,c(ncol(avg.rating), 1:(ncol(avg.rating)-1))]
avg.rating <- avg.rating %>% 
  mutate(month = as.Date(month),
         Year = year(month),
         Month_ = month(month),
         Month = factor(paste( Year, Month_, sep = "-")),
         Month = factor(Month, levels = Month)) %>% 
  select(-Year, -Month_, -month) 

count.rating <- count.rating %>% 
  as.data.frame() 
count.rating$month <- row.names(count.rating)
# avg.rating <- avg.rating[,c(ncol(avg.rating), 1:(ncol(avg.rating)-1))]
count.rating <- count.rating %>% 
  mutate(month = as.Date(month),
         Year = year(month),
         Month_ = month(month),
         Month = factor(paste( Year, Month_, sep = "-")),
         Month = factor(Month, levels = Month)) %>% 
  select(-Year, -Month_, -month)
```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
avg.plot <- avg.rating %>% 
  ggplot(aes(x= Month, y = Rating, group = 1)) +
  geom_line(lwd = 1.5, colour = "#E93434") +
  scale_y_continuous(limits = c(1.0, 5.5), breaks = seq(1.0, 10.0, 1.1), 
                     name = "Average Rating/month") +
  labs(title = "Average Month Rating", x = "Month") +
  theme(title = element_text(family = "Lucida Sans Unicode", size = 12, face = "bold"),
        plot.title = element_text(hjust = 0.5),
        axis.title = element_text(size = 10, vjust = 0.5),
        axis.line = element_line(colour = "grey70", size = 0.8),
        panel.background = element_blank(),
        panel.grid.major = element_line(colour = "grey70", linetype = 1),
        panel.grid.minor.y = element_blank(),
        plot.margin = margin(.5, .5, .5, .5, "cm"),
        plot.background = element_rect(colour = "grey", fill = "#E1E1E1", size = 0.8))

count.plot <- count.rating %>% 
  ggplot(aes(x= Month, y = Rating, group = 1)) +
  geom_line(lwd = 1.5, colour = "#E93434") +
  # scale_y_continuous(limits = c(1.0, 5.5), breaks = seq(1.0, 10.0, 1.1), 
                     # name = "Average Count") +
  labs(title = "Number Review per Month", x = "Month") +
  theme(title = element_text(family = "Lucida Sans Unicode", size = 12, face = "bold"),
        plot.title = element_text(hjust = 0.5),
        axis.title = element_text(size = 10, vjust = 0.5),
        axis.line = element_line(colour = "grey70", size = 0.8),
        panel.background = element_blank(),
        panel.grid.major = element_line(colour = "grey70", linetype = 1),
        panel.grid.minor.y = element_blank(),
        plot.margin = margin(.5, .5, .5, .5, "cm"),
        plot.background = element_rect(colour = "grey", fill = "#E1E1E1", size = 0.8))

library(gridExtra)
grid.arrange(avg.plot, count.plot, nrow =2)
```

